<center>

# Affordability of Residential Real Estate in Warsaw

---

**R-Bootcamp Project – W.MSCIDS_RB01.H2501**

Alena Ploshchansky · Rita Ahlborn

*Master of Science in Real Estate*

*Minor in Data Science*

Lucerne University of Applied Sciences and Arts

January 28, 2026

---

</center>


## **1. Introduction and Hypothesis**


### 1.1 Background and purpose of the project


---


## **2. Data Description**
Sources and types of data will be explained here. how many columns/rows, what kind of variables, etc.

```{r libraries, include = FALSE}
# Load required libraries
# Here maybe we should separate libtraries based on usage
library(dplyr)
library(ggplot2)
library(tidyr)
library(readxl)
library(janitor)
library(stringi)
library(stringr)
library(ggmap)
library(tidygeocoder)
library(writexl)
library(readr)

# Libraries for R markdown
library(knitr)
library(rmarkdown)

# To be updated ...

```


```{r data, include = FALSE}
#### Data set ####
## load data and inspection

## Prices data set
prices <- read_excel("Prices.xlsx")
head(prices)
dim(prices)

## Density data set
density <- read_excel("Density.xlsx", sheet="TABLE")
head(density)
dim(density)

## Median wage data set
median_wage <- read_excel("MedianWage.xlsx", sheet="TABLE")
head(median_wage)
dim(median_wage)

## Data check
glimpse(prices)
glimpse(density)
glimpse(median_wage)

```

---


## **3. Data Preparation**
In this chapter we describe the datasets we have as well as prepare it for further
analysis. We clean it, transform it and merge it into one final dataset.




### 3.1 Data Cleaning and transformation
This chapter is dedicated to cleaning and transforming each dataset separately.
After all the manipulations we will have three clean datasets ready for merging.
We will merge them in this chapter as well.
We have 3 datasets: prices, density, median_wage.

#### *3.1.1 Price Data*
Here we check for missing values and clean the data. We remove columns that are not needed.

```{r prices_values, include = FALSE}
## Check for missing values
sum(is.na(prices))
## Remove and change polish letters, convert to lower case
clean_prices <- prices %>%
  clean_names() %>%
  mutate(across(where(is.character),
            ~ tolower(stri_trans_general(., "Latin-ASCII"))))

## Check cleaned data
glimpse(clean_prices)

## Remove unnecessary columns
clean_prices <- clean_prices %>%
  select(-c("zrodlo_informacji", "cena_wartosc", "waluta", "numer_budynku"))

```
Here we create new variables: price per sqm, log price per sqm, etc.
First is geo data
```{r prices_geo, include = FALSE}
## Coordinates data type conversion and save
if (!file.exists("streets_geo.rds")) {

  streets_geo <- clean_prices %>%
    distinct(ulica) %>%
    mutate(address = paste0(ulica, ", Warsaw, Poland")) %>%
    geocode(
      address = address,
      method = "osm",
      lat = latitude,
      long = longitude
    )

  saveRDS(streets_geo, "streets_geo.rds")
}

# Load saved geo data
streets_geo <- readRDS("streets_geo.rds")

clean_prices <- clean_prices %>%
  left_join(streets_geo, by = "ulica")
```


```{r prices_cleaning, include = FALSE}

## Remove unnecessary columns
clean_prices <- clean_prices %>%
select(-address)

## Check final price data for missing values
sum(is.na(clean_prices))
glimpse(clean_prices)

## Delete rows with missing coordinates
clean_prices <- clean_prices %>%
filter(!is.na(latitude) & !is.na(longitude))
```

```{r prices_age, include = FALSE}
## Create building age groups
clean_prices <- clean_prices %>%
mutate(
building_age_group = case_when(
rok_budowy < 1960 ~ "very_old",
rok_budowy >= 1960 & rok_budowy < 2010 ~ "old",
rok_budowy >= 2010 & rok_budowy <= 2025 ~ "new",
TRUE ~ NA_character_))
```

```{r prices_date, include = FALSE}
## Date conversion
clean_prices <- clean_prices %>%
mutate(quarter_only = str_extract(data_transakcji_wyceny, "q[1-4]")) %>% # we left quarter only as all the data is from 2025
select(-data_transakcji_wyceny)
```

``` {r prices_log, include = FALSE}
clean_prices <- clean_prices %>%
relocate(quarter_only, .before = cena_wartosc_1m2) %>%
mutate(log_price_sqm = log(cena_wartosc_1m2)) %>%
relocate(log_price_sqm, .after = cena_wartosc_1m2)
```

#### *3.1.2 Wage Data*
Here we clean the wage data set and convert it to quarterly median wage.

``` {r wage_cleaning, include = FALSE}
# Removing missing Values and unnecessary columns
clean_wage <- median_wage %>%
select(-Code, -Name) %>%
slice(-c(1, 2, 3, 4))

#Wide to Long
clean_wage <- clean_wage %>%
pivot_longer(
cols = everything(),
names_to = "month",
values_to = "median_wage"
) %>%
mutate(median_wage = readr::parse_number(median_wage))
```

``` {r wage_quarter, include = FALSE}

# Convert wage median to quarterly median

wage_quarterly <- clean_wage %>%
mutate(
quarter = case_when(
month %in% c("January", "February", "March") ~ "q1",
month %in% c("April", "May", "June")         ~ "q2",
month %in% c("July", "August", "September")  ~ "q3",
))
wage_quarterly <- wage_quarterly %>%
group_by(quarter) %>%
summarise(
median_wage_q = mean(median_wage, na.rm = TRUE),
.groups = "drop"
)
```

``` {r wage_log, include = FALSE}
# Add log median wage quarterly
wage_quarterly <- wage_quarterly %>%
mutate(log_median_wage_q = log(median_wage_q))
```

#### *3.1.3 Density Data*

Here we will explain cleaning steps for Density data set.

``` {r density_cleaning, include = FALSE}
# Clean Density data set
# Cleaning the Polish letters and NAs from Density data set

clean_density <- density %>%
clean_names() %>%
select(-code) %>%
mutate(across(where(is.character),
~ tolower(stri_trans_general(., "Latin-ASCII"))))%>%

# remove missing values
na.omit()

# Erase first 2 rows and Distric 8 from the name

clean_density <- clean_density %>%
slice(-c(1, 2)) %>%                                   # remove first 2 rows
mutate(
name = str_remove(name, "\\s*-\\s*district\\s*\\(8\\)")
)
```

### 3.2 Data merging
Here we merge the three cleaned datasets into one final dataset for analysis.

``` {r data_merge, include = FALSE}
# Merging all datasets into one final dataset for analysis
final_data <- clean_prices %>%
left_join(clean_density, by = c("dzielnica" = "name")) %>%
left_join(wage_quarterly, by = c("quarter_only" = "quarter"))
# Check final data
glimpse(final_data)
```
---


## **4. Data Analysis**


### 4.1 Descriptive Statistics

#### *4.1.1 Summary Statistics*

#### *4.1.2 Distribution and Visualization*

### 4.2 Hypotheses

#### *4.2.1 Hypothesis 1*

Neighborhoods with higher density show lower prices per sqm than neighborhoods with lower density

1. Simple linear regression: log_price_sqm ~ log_density
2. Map ??


#### *4.2.2 Hypothesis 2*

The Vistula River represents a major spatial divide within Warsaw. Historically, the left bank has concentrated economic activity, central business districts, and higher-income neighborhoods, while the right bank has been more residential and, in some cases, less developed. These differences may translate into systematic affordability gaps between the two sides of the river.

We test whether higher population density is associated with lower residential prices per square meter.


1. Affordability calculation
``` {r affordability, include = FALSE}
left_bank <- c(
  "bemowo", "bielany", "mokotow", "ochota",
  "srodmiescie", "ursynow", "wola",
  "zoliborz", "wlochy", "ursus"
)

right_bank <- c(
  "bialoleka", "praga-polnoc", "praga-poludnie",
  "targowek", "rembertow", "wawer", "wesola"
)

clean_prices_h2 <- clean_prices %>%
  mutate(
    river_bank = case_when(
      dzielnica %in% left_bank  ~ "Left bank",
      dzielnica %in% right_bank ~ "Right bank",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(river_bank))

clean_prices_h2 <- clean_prices_h2 %>%
  left_join(
    wage_quarterly,
    by = c("quarter_only" = "quarter")
  )

clean_prices_h2 <- clean_prices_h2 %>%
  mutate(
    log_affordability = log_price_sqm - log(median_wage_q)
  )

2. T-test
3. Visuals: boxplot of affordability by bank


#### *4.2.3 Hypothesis 3*

Newer buildings are less affordable than older and very old buildings.

1. T-test
2. bla bla

---


## **5. Discussion and Limitations**


---


## **6. Conclusion**
